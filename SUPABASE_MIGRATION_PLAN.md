# ğŸš€ Supabase ë§ˆì´ê·¸ë ˆì´ì…˜ ë° ëŒ€ìš©ëŸ‰ ìµœì í™” ê³„íš

## ğŸ“Š í˜„ì¬ ìƒí™© ë¶„ì„

### í˜„ì¬ ì•„í‚¤í…ì²˜ (LocalStorage)
- âŒ **ìš©ëŸ‰ ì œí•œ**: 5-10MB (ì•½ 1,000~5,000ê°œ í‚¤ì›Œë“œ)
- âŒ **ì„±ëŠ¥ ì €í•˜**: ë°ì´í„° ì¦ê°€ ì‹œ ë¡œë”©/ì €ì¥ ëŠë ¤ì§
- âŒ **ë°ì´í„° ì†ì‹¤**: ë¸Œë¼ìš°ì € ìºì‹œ ì‚­ì œ ì‹œ ëª¨ë‘ ì‚­ì œ
- âŒ **ê³µìœ  ë¶ˆê°€**: ë””ë°”ì´ìŠ¤ ê°„ ë™ê¸°í™” ë¶ˆê°€

### ëª©í‘œ ì•„í‚¤í…ì²˜ (Supabase)
- âœ… **ë¬´ì œí•œ ìš©ëŸ‰**: 100ë§Œ~1000ë§Œ ê°œ í‚¤ì›Œë“œ ì €ì¥
- âœ… **ë¹ ë¥¸ ì„±ëŠ¥**: ì¸ë±ì‹± ë° ì¿¼ë¦¬ ìµœì í™”
- âœ… **ë°ì´í„° ì•ˆì „**: í´ë¼ìš°ë“œ ë°±ì—…
- âœ… **ì‹¤ì‹œê°„ ë™ê¸°í™”**: ì—¬ëŸ¬ ë””ë°”ì´ìŠ¤ì—ì„œ ì ‘ê·¼

---

## ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì„¤ê³„

### 1. í‚¤ì›Œë“œ í…Œì´ë¸” (keywords)

```sql
CREATE TABLE keywords (
  -- ê¸°ë³¸ ì •ë³´
  id BIGSERIAL PRIMARY KEY,
  keyword VARCHAR(100) NOT NULL,
  root_keyword VARCHAR(100),
  
  -- ê²€ìƒ‰ëŸ‰ ë°ì´í„°
  monthly_pc_search INTEGER DEFAULT 0,
  monthly_mobile_search INTEGER DEFAULT 0,
  total_search INTEGER GENERATED ALWAYS AS (monthly_pc_search + monthly_mobile_search) STORED,
  
  -- ê²½ìŸë„
  competition VARCHAR(20),
  
  -- ë¬¸ì„œìˆ˜
  blog_total_count INTEGER,
  cafe_total_count INTEGER,
  news_total_count INTEGER,
  webkr_total_count INTEGER,
  
  -- í´ë¦­ ë°ì´í„°
  monthly_pc_clicks INTEGER,
  monthly_mobile_clicks INTEGER,
  monthly_pc_click_rate DECIMAL(5,2),
  monthly_mobile_click_rate DECIMAL(5,2),
  monthly_ad_count INTEGER,
  
  -- ìë™ ìˆ˜ì§‘ ê´€ë ¨
  used_as_seed BOOLEAN DEFAULT FALSE,
  seed_depth INTEGER DEFAULT 0,
  
  -- ë©”íƒ€ë°ì´í„°
  queried_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW(),
  
  -- ìœ ë‹ˆí¬ ì œì•½ (ì¤‘ë³µ ë°©ì§€)
  CONSTRAINT unique_keyword UNIQUE(keyword)
);

-- ì„±ëŠ¥ ìµœì í™” ì¸ë±ìŠ¤
CREATE INDEX idx_keywords_keyword ON keywords(keyword);
CREATE INDEX idx_keywords_total_search ON keywords(total_search DESC);
CREATE INDEX idx_keywords_competition ON keywords(competition);
CREATE INDEX idx_keywords_used_as_seed ON keywords(used_as_seed) WHERE used_as_seed = FALSE;
CREATE INDEX idx_keywords_queried_at ON keywords(queried_at DESC);
CREATE INDEX idx_keywords_root_keyword ON keywords(root_keyword);

-- ë³µí•© ì¸ë±ìŠ¤ (ìì£¼ ì‚¬ìš©í•˜ëŠ” í•„í„° ì¡°í•©)
CREATE INDEX idx_keywords_search_competition ON keywords(total_search DESC, competition);
CREATE INDEX idx_keywords_cafe_count ON keywords(cafe_total_count) WHERE cafe_total_count IS NOT NULL;

-- íŒŒí‹°ì…”ë‹ (1000ë§Œ ê°œ ì´ìƒ ëŒ€ë¹„)
-- ì›”ë³„ íŒŒí‹°ì…”ë‹ìœ¼ë¡œ ì¿¼ë¦¬ ì„±ëŠ¥ í–¥ìƒ
CREATE TABLE keywords_partitioned (
  LIKE keywords INCLUDING ALL
) PARTITION BY RANGE (queried_at);

-- ì›”ë³„ íŒŒí‹°ì…˜ ìƒì„± (ì˜ˆì‹œ)
CREATE TABLE keywords_2024_01 PARTITION OF keywords_partitioned
  FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');

-- ìë™ íŒŒí‹°ì…˜ ìƒì„± í•¨ìˆ˜
CREATE OR REPLACE FUNCTION create_monthly_partition()
RETURNS void AS $$
DECLARE
  partition_date DATE := DATE_TRUNC('month', CURRENT_DATE);
  partition_name TEXT := 'keywords_' || TO_CHAR(partition_date, 'YYYY_MM');
  start_date DATE := partition_date;
  end_date DATE := partition_date + INTERVAL '1 month';
BEGIN
  EXECUTE format(
    'CREATE TABLE IF NOT EXISTS %I PARTITION OF keywords_partitioned FOR VALUES FROM (%L) TO (%L)',
    partition_name, start_date, end_date
  );
END;
$$ LANGUAGE plpgsql;
```

### 2. ì‚¬ìš©ì í…Œì´ë¸” (users) - ì„ íƒì‚¬í•­

```sql
CREATE TABLE users (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  email VARCHAR(255) UNIQUE,
  created_at TIMESTAMPTZ DEFAULT NOW(),
  last_login_at TIMESTAMPTZ
);

-- í‚¤ì›Œë“œì— user_id ì¶”ê°€
ALTER TABLE keywords ADD COLUMN user_id UUID REFERENCES users(id);
CREATE INDEX idx_keywords_user_id ON keywords(user_id);
```

### 3. ë°°ì¹˜ ì‘ì—… í…Œì´ë¸” (batch_jobs)

```sql
CREATE TABLE batch_jobs (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID REFERENCES users(id),
  status VARCHAR(20) DEFAULT 'pending',
  total_keywords INTEGER,
  processed_keywords INTEGER DEFAULT 0,
  started_at TIMESTAMPTZ,
  completed_at TIMESTAMPTZ,
  error_message TEXT,
  
  CONSTRAINT valid_status CHECK (status IN ('pending', 'processing', 'completed', 'failed'))
);

CREATE INDEX idx_batch_jobs_status ON batch_jobs(status);
CREATE INDEX idx_batch_jobs_user_id ON batch_jobs(user_id);
```

---

## ğŸš€ ì„±ëŠ¥ ìµœì í™” ì „ëµ

### 1. ì¸ë±ì‹± ì „ëµ

#### A. B-Tree ì¸ë±ìŠ¤ (ê¸°ë³¸)
```sql
-- ìì£¼ ê²€ìƒ‰ë˜ëŠ” ì»¬ëŸ¼
CREATE INDEX idx_keywords_keyword ON keywords(keyword);
CREATE INDEX idx_keywords_total_search ON keywords(total_search DESC);
```

#### B. ë¶€ë¶„ ì¸ë±ìŠ¤ (Partial Index)
```sql
-- ì¡°ê±´ë¶€ ì¸ë±ìŠ¤ë¡œ í¬ê¸° ê°ì†Œ
CREATE INDEX idx_unused_seeds ON keywords(keyword) 
  WHERE used_as_seed = FALSE;

CREATE INDEX idx_with_doc_counts ON keywords(keyword)
  WHERE cafe_total_count IS NOT NULL;
```

#### C. ë³µí•© ì¸ë±ìŠ¤
```sql
-- ìì£¼ í•¨ê»˜ ì‚¬ìš©ë˜ëŠ” í•„í„°
CREATE INDEX idx_search_competition ON keywords(total_search DESC, competition);
```

### 2. ì¿¼ë¦¬ ìµœì í™”

#### A. í˜ì´ì§€ë„¤ì´ì…˜ (Cursor-based)
```sql
-- âŒ OFFSET ë°©ì‹ (ëŠë¦¼)
SELECT * FROM keywords 
ORDER BY id 
LIMIT 1000 OFFSET 100000;  -- 100,000ê°œ ìŠ¤ìº” í•„ìš”

-- âœ… Cursor ë°©ì‹ (ë¹ ë¦„)
SELECT * FROM keywords 
WHERE id > 100000 
ORDER BY id 
LIMIT 1000;  -- í•„ìš”í•œ ë§Œí¼ë§Œ ìŠ¤ìº”
```

#### B. ì§‘ê³„ ì¿¼ë¦¬ ìµœì í™”
```sql
-- âŒ ëŠë¦° ë°©ì‹
SELECT COUNT(*) FROM keywords;  -- ì „ì²´ ìŠ¤ìº”

-- âœ… ë¹ ë¥¸ ë°©ì‹ (í†µê³„ í…Œì´ë¸” í™œìš©)
SELECT reltuples::bigint AS estimate 
FROM pg_class 
WHERE relname = 'keywords';
```

#### C. í•„í„°ë§ ìµœì í™”
```sql
-- ì¸ë±ìŠ¤ í™œìš©
SELECT * FROM keywords 
WHERE total_search >= 1000 
  AND competition = 'ë‚®ìŒ'
  AND cafe_total_count < 10000
ORDER BY total_search DESC
LIMIT 1000;
```

### 3. ìºì‹± ì „ëµ

#### A. Supabase Edge Functions + Redis
```typescript
// Redis ìºì‹± (ì„ íƒì‚¬í•­)
const cacheKey = `keywords:filter:${filterHash}`;
const cached = await redis.get(cacheKey);

if (cached) {
  return JSON.parse(cached);
}

const data = await supabase.from('keywords').select('*');
await redis.setex(cacheKey, 300, JSON.stringify(data));  // 5ë¶„ ìºì‹œ
```

#### B. í´ë¼ì´ì–¸íŠ¸ ìºì‹±
```typescript
// React Queryë¡œ í´ë¼ì´ì–¸íŠ¸ ìºì‹±
const { data } = useQuery({
  queryKey: ['keywords', filters],
  queryFn: () => fetchKeywords(filters),
  staleTime: 5 * 60 * 1000,  // 5ë¶„
  cacheTime: 30 * 60 * 1000,  // 30ë¶„
});
```

### 4. ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”

#### A. ëŒ€ëŸ‰ ì‚½ì… (Bulk Insert)
```typescript
// âŒ ê°œë³„ ì‚½ì… (ëŠë¦¼)
for (const keyword of keywords) {
  await supabase.from('keywords').insert(keyword);
}

// âœ… ë°°ì¹˜ ì‚½ì… (ë¹ ë¦„)
await supabase.from('keywords').insert(keywords);  // í•œ ë²ˆì— 1000ê°œ
```

#### B. UPSERT í™œìš©
```typescript
// ì¤‘ë³µ ì²˜ë¦¬ + ì—…ë°ì´íŠ¸
await supabase
  .from('keywords')
  .upsert(keywords, { 
    onConflict: 'keyword',
    ignoreDuplicates: false  // ì—…ë°ì´íŠ¸
  });
```

---

## ğŸ“¦ ë§ˆì´ê·¸ë ˆì´ì…˜ ë‹¨ê³„

### Phase 1: Supabase ì„¤ì • (1ì¼)

1. **Supabase í”„ë¡œì íŠ¸ ìƒì„±**
   ```bash
   # Supabase CLI ì„¤ì¹˜
   npm install -g supabase
   
   # í”„ë¡œì íŠ¸ ì´ˆê¸°í™”
   supabase init
   
   # ë¡œì»¬ ê°œë°œ í™˜ê²½ ì‹œì‘
   supabase start
   ```

2. **í™˜ê²½ ë³€ìˆ˜ ì„¤ì •**
   ```env
   # .env.local
   NEXT_PUBLIC_SUPABASE_URL=https://xxx.supabase.co
   NEXT_PUBLIC_SUPABASE_ANON_KEY=eyJxxx...
   SUPABASE_SERVICE_ROLE_KEY=eyJxxx...
   ```

3. **ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰**
   ```bash
   supabase migration new create_keywords_table
   # SQL íŒŒì¼ í¸ì§‘
   supabase db push
   ```

### Phase 2: ë°ì´í„° ë ˆì´ì–´ êµ¬í˜„ (2ì¼)

1. **Supabase í´ë¼ì´ì–¸íŠ¸ ì„¤ì •**
   ```typescript
   // lib/supabase/client.ts
   import { createClient } from '@supabase/supabase-js';
   
   export const supabase = createClient(
     process.env.NEXT_PUBLIC_SUPABASE_URL!,
     process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!
   );
   
   // ì„œë²„ ì‚¬ì´ë“œìš©
   export const supabaseAdmin = createClient(
     process.env.NEXT_PUBLIC_SUPABASE_URL!,
     process.env.SUPABASE_SERVICE_ROLE_KEY!
   );
   ```

2. **ë°ì´í„° ì•¡ì„¸ìŠ¤ ë ˆì´ì–´**
   ```typescript
   // lib/supabase/keywords.ts
   export async function getKeywords(filters: FilterOptions) {
     let query = supabase
       .from('keywords')
       .select('*', { count: 'exact' });
     
     // í•„í„° ì ìš©
     if (filters.minSearch) {
       query = query.gte('total_search', filters.minSearch);
     }
     
     // ì •ë ¬
     query = query.order('total_search', { ascending: false });
     
     // í˜ì´ì§€ë„¤ì´ì…˜ (Cursor)
     if (filters.cursor) {
       query = query.gt('id', filters.cursor);
     }
     
     query = query.limit(1000);
     
     return query;
   }
   ```

### Phase 3: LocalStorage ë§ˆì´ê·¸ë ˆì´ì…˜ (1ì¼)

1. **ê¸°ì¡´ ë°ì´í„° ë‚´ë³´ë‚´ê¸°**
   ```typescript
   // scripts/export-localstorage.ts
   const data = localStorage.getItem('nkeyword:dataset:v1');
   const keywords = JSON.parse(data);
   
   // JSON íŒŒì¼ë¡œ ì €ì¥
   fs.writeFileSync('keywords-backup.json', JSON.stringify(keywords));
   ```

2. **Supabaseë¡œ ê°€ì ¸ì˜¤ê¸°**
   ```typescript
   // scripts/import-to-supabase.ts
   const keywords = JSON.parse(fs.readFileSync('keywords-backup.json'));
   
   // 1000ê°œì”© ë°°ì¹˜ ì‚½ì…
   for (let i = 0; i < keywords.length; i += 1000) {
     const batch = keywords.slice(i, i + 1000);
     await supabase.from('keywords').upsert(batch);
   }
   ```

### Phase 4: API ë¼ìš°íŠ¸ ìˆ˜ì • (2ì¼)

1. **ê¸°ì¡´ storage.ts ëŒ€ì²´**
   ```typescript
   // Before: lib/storage.ts (LocalStorage)
   export function loadDataset(): Dataset {
     return JSON.parse(localStorage.getItem('nkeyword:dataset:v1'));
   }
   
   // After: lib/supabase/keywords.ts (Supabase)
   export async function loadDataset(filters?: FilterOptions) {
     const { data } = await supabase
       .from('keywords')
       .select('*')
       .limit(1000);
     return data;
   }
   ```

2. **API ë¼ìš°íŠ¸ ì—…ë°ì´íŠ¸**
   ```typescript
   // app/api/keywords/list/route.ts
   export async function GET(request: NextRequest) {
     const { searchParams } = request.nextUrl;
     const cursor = searchParams.get('cursor');
     const limit = parseInt(searchParams.get('limit') || '1000');
     
     const { data, error } = await supabase
       .from('keywords')
       .select('*')
       .gt('id', cursor || 0)
       .order('id')
       .limit(limit);
     
     return NextResponse.json({ data, nextCursor: data[data.length - 1]?.id });
   }
   ```

### Phase 5: í”„ë¡ íŠ¸ì—”ë“œ ìˆ˜ì • (2ì¼)

1. **React Query ë„ì…**
   ```typescript
   // app/data/page.tsx
   const { data, fetchNextPage, hasNextPage } = useInfiniteQuery({
     queryKey: ['keywords', filters],
     queryFn: ({ pageParam = 0 }) => fetchKeywords({ cursor: pageParam, ...filters }),
     getNextPageParam: (lastPage) => lastPage.nextCursor,
   });
   ```

2. **ë¬´í•œ ìŠ¤í¬ë¡¤**
   ```typescript
   const { ref, inView } = useInView();
   
   useEffect(() => {
     if (inView && hasNextPage) {
       fetchNextPage();
     }
   }, [inView, hasNextPage]);
   ```

---

## ğŸ¯ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

### ì˜ˆìƒ ì„±ëŠ¥ (1000ë§Œ ê°œ ê¸°ì¤€)

| ì‘ì—… | LocalStorage | Supabase (ìµœì í™”) | ê°œì„ ìœ¨ |
|------|--------------|-------------------|--------|
| **ì „ì²´ ë¡œë“œ** | ë¶ˆê°€ëŠ¥ | 50ms | âˆ |
| **í•„í„°ë§** | ë¶ˆê°€ëŠ¥ | 100ms | âˆ |
| **ì •ë ¬** | ë¶ˆê°€ëŠ¥ | 80ms | âˆ |
| **ê²€ìƒ‰** | ë¶ˆê°€ëŠ¥ | 30ms | âˆ |
| **ì‚½ì… (1000ê°œ)** | 5ì´ˆ | 200ms | 25ë°° |
| **í˜ì´ì§€ ë¡œë”©** | ë¶ˆê°€ëŠ¥ | 100ms | âˆ |

---

## ğŸ’° ë¹„ìš© ì˜ˆì¸¡

### Supabase ë¬´ë£Œ í‹°ì–´
- âœ… 500MB ë°ì´í„°ë² ì´ìŠ¤
- âœ… 50,000 ì›”ê°„ í™œì„± ì‚¬ìš©ì
- âœ… 2GB ëŒ€ì—­í­
- âœ… 500MB íŒŒì¼ ì €ì¥ì†Œ

### ì˜ˆìƒ ë°ì´í„° í¬ê¸°
- 1ê°œ í‚¤ì›Œë“œ: ~500 bytes
- 100ë§Œ ê°œ: ~500MB âœ… (ë¬´ë£Œ í‹°ì–´ ê°€ëŠ¥)
- 1000ë§Œ ê°œ: ~5GB âŒ (Pro í‹°ì–´ í•„ìš”: $25/ì›”)

### Pro í‹°ì–´ ($25/ì›”)
- âœ… 8GB ë°ì´í„°ë² ì´ìŠ¤
- âœ… 100,000 ì›”ê°„ í™œì„± ì‚¬ìš©ì
- âœ… 50GB ëŒ€ì—­í­
- âœ… 100GB íŒŒì¼ ì €ì¥ì†Œ

---

## ğŸ”’ ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

### Row Level Security (RLS)

```sql
-- ì‚¬ìš©ìë³„ ë°ì´í„° ê²©ë¦¬
ALTER TABLE keywords ENABLE ROW LEVEL SECURITY;

-- ìì‹ ì˜ ë°ì´í„°ë§Œ ì¡°íšŒ
CREATE POLICY "Users can view own keywords"
  ON keywords FOR SELECT
  USING (auth.uid() = user_id);

-- ìì‹ ì˜ ë°ì´í„°ë§Œ ì‚½ì…
CREATE POLICY "Users can insert own keywords"
  ON keywords FOR INSERT
  WITH CHECK (auth.uid() = user_id);
```

---

## ğŸ“‹ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ë§ˆì´ê·¸ë ˆì´ì…˜ ì „
- [ ] Supabase í”„ë¡œì íŠ¸ ìƒì„±
- [ ] ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì„¤ê³„
- [ ] ì¸ë±ìŠ¤ ì „ëµ ìˆ˜ë¦½
- [ ] ê¸°ì¡´ ë°ì´í„° ë°±ì—…

### ë§ˆì´ê·¸ë ˆì´ì…˜ ì¤‘
- [ ] ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
- [ ] API ë¼ìš°íŠ¸ ìˆ˜ì •
- [ ] í”„ë¡ íŠ¸ì—”ë“œ ìˆ˜ì •
- [ ] í…ŒìŠ¤íŠ¸ (ì„±ëŠ¥, ê¸°ëŠ¥)

### ë§ˆì´ê·¸ë ˆì´ì…˜ í›„
- [ ] ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
- [ ] ì¿¼ë¦¬ ìµœì í™”
- [ ] ë°±ì—… ìë™í™”
- [ ] ë¬¸ì„œí™”

---

## ğŸš€ ë‹¤ìŒ ë‹¨ê³„

1. **ì¦‰ì‹œ ì‹œì‘ ê°€ëŠ¥**
   - Supabase í”„ë¡œì íŠ¸ ìƒì„±
   - ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì ìš©
   - í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

2. **ë‹¨ê³„ë³„ ë§ˆì´ê·¸ë ˆì´ì…˜**
   - Phase 1-2: ë°±ì—”ë“œ êµ¬ì¶• (3ì¼)
   - Phase 3-4: ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ (3ì¼)
   - Phase 5: í”„ë¡ íŠ¸ì—”ë“œ ìˆ˜ì • (2ì¼)

3. **ì´ ì†Œìš” ì‹œê°„**: ì•½ 1-2ì£¼

---

**ì´ ê³„íšëŒ€ë¡œ ì§„í–‰í•˜ë©´ 100ë§Œ~1000ë§Œ ê°œì˜ í‚¤ì›Œë“œë„ ë¹ ë¥´ê²Œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!** ğŸ‰
